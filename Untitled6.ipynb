{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lafta/deep-dream-/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vunkOrR2nQhI",
        "outputId": "fc3bbfe3-2ffd-48af-c180-96043baf883f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh4F3PMfwkdy",
        "outputId": "f9eed0cc-d15c-4669-d122-be13580307b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.4.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (0.38.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (2.11.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.51.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.12.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model\n",
        "#model = ResNet50(weights='imagenet')\n",
        "from tensorflow import keras\n",
        "model = keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
        "# Iterate over the layers in the ResNet50 model\n",
        "for layer in model.layers:\n",
        "  print(f'{layer.name}---> {layer.output_shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkvkidudwn7l",
        "outputId": "22794af9-de59-4a53-f244-4c61c79a8598"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "input_6---> [(None, None, None, 3)]\n",
            "conv1_pad---> (None, None, None, 3)\n",
            "conv1_conv---> (None, None, None, 64)\n",
            "conv1_bn---> (None, None, None, 64)\n",
            "conv1_relu---> (None, None, None, 64)\n",
            "pool1_pad---> (None, None, None, 64)\n",
            "pool1_pool---> (None, None, None, 64)\n",
            "conv2_block1_1_conv---> (None, None, None, 64)\n",
            "conv2_block1_1_bn---> (None, None, None, 64)\n",
            "conv2_block1_1_relu---> (None, None, None, 64)\n",
            "conv2_block1_2_conv---> (None, None, None, 64)\n",
            "conv2_block1_2_bn---> (None, None, None, 64)\n",
            "conv2_block1_2_relu---> (None, None, None, 64)\n",
            "conv2_block1_0_conv---> (None, None, None, 256)\n",
            "conv2_block1_3_conv---> (None, None, None, 256)\n",
            "conv2_block1_0_bn---> (None, None, None, 256)\n",
            "conv2_block1_3_bn---> (None, None, None, 256)\n",
            "conv2_block1_add---> (None, None, None, 256)\n",
            "conv2_block1_out---> (None, None, None, 256)\n",
            "conv2_block2_1_conv---> (None, None, None, 64)\n",
            "conv2_block2_1_bn---> (None, None, None, 64)\n",
            "conv2_block2_1_relu---> (None, None, None, 64)\n",
            "conv2_block2_2_conv---> (None, None, None, 64)\n",
            "conv2_block2_2_bn---> (None, None, None, 64)\n",
            "conv2_block2_2_relu---> (None, None, None, 64)\n",
            "conv2_block2_3_conv---> (None, None, None, 256)\n",
            "conv2_block2_3_bn---> (None, None, None, 256)\n",
            "conv2_block2_add---> (None, None, None, 256)\n",
            "conv2_block2_out---> (None, None, None, 256)\n",
            "conv2_block3_1_conv---> (None, None, None, 64)\n",
            "conv2_block3_1_bn---> (None, None, None, 64)\n",
            "conv2_block3_1_relu---> (None, None, None, 64)\n",
            "conv2_block3_2_conv---> (None, None, None, 64)\n",
            "conv2_block3_2_bn---> (None, None, None, 64)\n",
            "conv2_block3_2_relu---> (None, None, None, 64)\n",
            "conv2_block3_3_conv---> (None, None, None, 256)\n",
            "conv2_block3_3_bn---> (None, None, None, 256)\n",
            "conv2_block3_add---> (None, None, None, 256)\n",
            "conv2_block3_out---> (None, None, None, 256)\n",
            "conv3_block1_1_conv---> (None, None, None, 128)\n",
            "conv3_block1_1_bn---> (None, None, None, 128)\n",
            "conv3_block1_1_relu---> (None, None, None, 128)\n",
            "conv3_block1_2_conv---> (None, None, None, 128)\n",
            "conv3_block1_2_bn---> (None, None, None, 128)\n",
            "conv3_block1_2_relu---> (None, None, None, 128)\n",
            "conv3_block1_0_conv---> (None, None, None, 512)\n",
            "conv3_block1_3_conv---> (None, None, None, 512)\n",
            "conv3_block1_0_bn---> (None, None, None, 512)\n",
            "conv3_block1_3_bn---> (None, None, None, 512)\n",
            "conv3_block1_add---> (None, None, None, 512)\n",
            "conv3_block1_out---> (None, None, None, 512)\n",
            "conv3_block2_1_conv---> (None, None, None, 128)\n",
            "conv3_block2_1_bn---> (None, None, None, 128)\n",
            "conv3_block2_1_relu---> (None, None, None, 128)\n",
            "conv3_block2_2_conv---> (None, None, None, 128)\n",
            "conv3_block2_2_bn---> (None, None, None, 128)\n",
            "conv3_block2_2_relu---> (None, None, None, 128)\n",
            "conv3_block2_3_conv---> (None, None, None, 512)\n",
            "conv3_block2_3_bn---> (None, None, None, 512)\n",
            "conv3_block2_add---> (None, None, None, 512)\n",
            "conv3_block2_out---> (None, None, None, 512)\n",
            "conv3_block3_1_conv---> (None, None, None, 128)\n",
            "conv3_block3_1_bn---> (None, None, None, 128)\n",
            "conv3_block3_1_relu---> (None, None, None, 128)\n",
            "conv3_block3_2_conv---> (None, None, None, 128)\n",
            "conv3_block3_2_bn---> (None, None, None, 128)\n",
            "conv3_block3_2_relu---> (None, None, None, 128)\n",
            "conv3_block3_3_conv---> (None, None, None, 512)\n",
            "conv3_block3_3_bn---> (None, None, None, 512)\n",
            "conv3_block3_add---> (None, None, None, 512)\n",
            "conv3_block3_out---> (None, None, None, 512)\n",
            "conv3_block4_1_conv---> (None, None, None, 128)\n",
            "conv3_block4_1_bn---> (None, None, None, 128)\n",
            "conv3_block4_1_relu---> (None, None, None, 128)\n",
            "conv3_block4_2_conv---> (None, None, None, 128)\n",
            "conv3_block4_2_bn---> (None, None, None, 128)\n",
            "conv3_block4_2_relu---> (None, None, None, 128)\n",
            "conv3_block4_3_conv---> (None, None, None, 512)\n",
            "conv3_block4_3_bn---> (None, None, None, 512)\n",
            "conv3_block4_add---> (None, None, None, 512)\n",
            "conv3_block4_out---> (None, None, None, 512)\n",
            "conv4_block1_1_conv---> (None, None, None, 256)\n",
            "conv4_block1_1_bn---> (None, None, None, 256)\n",
            "conv4_block1_1_relu---> (None, None, None, 256)\n",
            "conv4_block1_2_conv---> (None, None, None, 256)\n",
            "conv4_block1_2_bn---> (None, None, None, 256)\n",
            "conv4_block1_2_relu---> (None, None, None, 256)\n",
            "conv4_block1_0_conv---> (None, None, None, 1024)\n",
            "conv4_block1_3_conv---> (None, None, None, 1024)\n",
            "conv4_block1_0_bn---> (None, None, None, 1024)\n",
            "conv4_block1_3_bn---> (None, None, None, 1024)\n",
            "conv4_block1_add---> (None, None, None, 1024)\n",
            "conv4_block1_out---> (None, None, None, 1024)\n",
            "conv4_block2_1_conv---> (None, None, None, 256)\n",
            "conv4_block2_1_bn---> (None, None, None, 256)\n",
            "conv4_block2_1_relu---> (None, None, None, 256)\n",
            "conv4_block2_2_conv---> (None, None, None, 256)\n",
            "conv4_block2_2_bn---> (None, None, None, 256)\n",
            "conv4_block2_2_relu---> (None, None, None, 256)\n",
            "conv4_block2_3_conv---> (None, None, None, 1024)\n",
            "conv4_block2_3_bn---> (None, None, None, 1024)\n",
            "conv4_block2_add---> (None, None, None, 1024)\n",
            "conv4_block2_out---> (None, None, None, 1024)\n",
            "conv4_block3_1_conv---> (None, None, None, 256)\n",
            "conv4_block3_1_bn---> (None, None, None, 256)\n",
            "conv4_block3_1_relu---> (None, None, None, 256)\n",
            "conv4_block3_2_conv---> (None, None, None, 256)\n",
            "conv4_block3_2_bn---> (None, None, None, 256)\n",
            "conv4_block3_2_relu---> (None, None, None, 256)\n",
            "conv4_block3_3_conv---> (None, None, None, 1024)\n",
            "conv4_block3_3_bn---> (None, None, None, 1024)\n",
            "conv4_block3_add---> (None, None, None, 1024)\n",
            "conv4_block3_out---> (None, None, None, 1024)\n",
            "conv4_block4_1_conv---> (None, None, None, 256)\n",
            "conv4_block4_1_bn---> (None, None, None, 256)\n",
            "conv4_block4_1_relu---> (None, None, None, 256)\n",
            "conv4_block4_2_conv---> (None, None, None, 256)\n",
            "conv4_block4_2_bn---> (None, None, None, 256)\n",
            "conv4_block4_2_relu---> (None, None, None, 256)\n",
            "conv4_block4_3_conv---> (None, None, None, 1024)\n",
            "conv4_block4_3_bn---> (None, None, None, 1024)\n",
            "conv4_block4_add---> (None, None, None, 1024)\n",
            "conv4_block4_out---> (None, None, None, 1024)\n",
            "conv4_block5_1_conv---> (None, None, None, 256)\n",
            "conv4_block5_1_bn---> (None, None, None, 256)\n",
            "conv4_block5_1_relu---> (None, None, None, 256)\n",
            "conv4_block5_2_conv---> (None, None, None, 256)\n",
            "conv4_block5_2_bn---> (None, None, None, 256)\n",
            "conv4_block5_2_relu---> (None, None, None, 256)\n",
            "conv4_block5_3_conv---> (None, None, None, 1024)\n",
            "conv4_block5_3_bn---> (None, None, None, 1024)\n",
            "conv4_block5_add---> (None, None, None, 1024)\n",
            "conv4_block5_out---> (None, None, None, 1024)\n",
            "conv4_block6_1_conv---> (None, None, None, 256)\n",
            "conv4_block6_1_bn---> (None, None, None, 256)\n",
            "conv4_block6_1_relu---> (None, None, None, 256)\n",
            "conv4_block6_2_conv---> (None, None, None, 256)\n",
            "conv4_block6_2_bn---> (None, None, None, 256)\n",
            "conv4_block6_2_relu---> (None, None, None, 256)\n",
            "conv4_block6_3_conv---> (None, None, None, 1024)\n",
            "conv4_block6_3_bn---> (None, None, None, 1024)\n",
            "conv4_block6_add---> (None, None, None, 1024)\n",
            "conv4_block6_out---> (None, None, None, 1024)\n",
            "conv5_block1_1_conv---> (None, None, None, 512)\n",
            "conv5_block1_1_bn---> (None, None, None, 512)\n",
            "conv5_block1_1_relu---> (None, None, None, 512)\n",
            "conv5_block1_2_conv---> (None, None, None, 512)\n",
            "conv5_block1_2_bn---> (None, None, None, 512)\n",
            "conv5_block1_2_relu---> (None, None, None, 512)\n",
            "conv5_block1_0_conv---> (None, None, None, 2048)\n",
            "conv5_block1_3_conv---> (None, None, None, 2048)\n",
            "conv5_block1_0_bn---> (None, None, None, 2048)\n",
            "conv5_block1_3_bn---> (None, None, None, 2048)\n",
            "conv5_block1_add---> (None, None, None, 2048)\n",
            "conv5_block1_out---> (None, None, None, 2048)\n",
            "conv5_block2_1_conv---> (None, None, None, 512)\n",
            "conv5_block2_1_bn---> (None, None, None, 512)\n",
            "conv5_block2_1_relu---> (None, None, None, 512)\n",
            "conv5_block2_2_conv---> (None, None, None, 512)\n",
            "conv5_block2_2_bn---> (None, None, None, 512)\n",
            "conv5_block2_2_relu---> (None, None, None, 512)\n",
            "conv5_block2_3_conv---> (None, None, None, 2048)\n",
            "conv5_block2_3_bn---> (None, None, None, 2048)\n",
            "conv5_block2_add---> (None, None, None, 2048)\n",
            "conv5_block2_out---> (None, None, None, 2048)\n",
            "conv5_block3_1_conv---> (None, None, None, 512)\n",
            "conv5_block3_1_bn---> (None, None, None, 512)\n",
            "conv5_block3_1_relu---> (None, None, None, 512)\n",
            "conv5_block3_2_conv---> (None, None, None, 512)\n",
            "conv5_block3_2_bn---> (None, None, None, 512)\n",
            "conv5_block3_2_relu---> (None, None, None, 512)\n",
            "conv5_block3_3_conv---> (None, None, None, 2048)\n",
            "conv5_block3_3_bn---> (None, None, None, 2048)\n",
            "conv5_block3_add---> (None, None, None, 2048)\n",
            "conv5_block3_out---> (None, None, None, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the loss\n",
        "def calc_loss(input_image, model):\n",
        "    input_image_batch = tf.expand_dims(input_image, axis=0)\n",
        "    preprocessed_input = preprocess_input(input_image_batch.numpy().copy())\n",
        "\n",
        "    # Get the activations of a specific layer\n",
        "    layer_name = \"conv5_block2_1_bn\"\n",
        "    intermediate_layer_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "    intermediate_output = intermediate_layer_model(preprocessed_input)\n",
        "\n",
        "    # Define the loss\n",
        "    loss = tf.math.reduce_mean(intermediate_output)\n",
        "    return loss, intermediate_output\n",
        "\n",
        "# Call the calc_loss function and print the shape of intermediate_output\n",
        "loss, intermediate_output = calc_loss(input_image, model)\n",
        "print(intermediate_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UARSm4gGBAZu",
        "outputId": "e2327a8c-06c1-4367-9a66-064621e7d8f5"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 7, 7, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcW9z4q8PDeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Function to calculate the loss\n",
        "def calc_loss(input_image, model):\n",
        "    input_image_batch = tf.expand_dims(input_image, axis=0)\n",
        "    preprocessed_input = preprocess_input(input_image_batch.numpy().copy())\n",
        "\n",
        "    # Get the activations of a specific layer\n",
        "    layer_name = \"conv5_block2_1_bn\"\n",
        "    intermediate_layer_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "    intermediate_output = intermediate_layer_model(preprocessed_input)\n",
        "\n",
        "    # Define the loss\n",
        "    loss = tf.math.reduce_mean(intermediate_output)\n",
        "    return loss, intermediate_layer_model\n",
        "\n",
        "    '''"
      ],
      "metadata": {
        "id": "_lca9l_POy40"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Function to calculate the loss\n",
        "def calc_loss(input_image, model):\n",
        "    input_image_batch = tf.expand_dims(input_image, axis=0)\n",
        "    preprocessed_input = preprocess_input(input_image_batch.numpy().copy())\n",
        "\n",
        "    # Get the activations of a specific layer\n",
        "    layer_name = \"conv5_block2_1_bn\"\n",
        "    intermediate_layer_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "    intermediate_output = intermediate_layer_model(preprocessed_input)\n",
        "\n",
        "    \n",
        "\n",
        "    # Define the loss\n",
        "    loss = tf.math.reduce_mean(intermediate_output)\n",
        "    return loss, intermediate_layer_model\n",
        "\n",
        "    print(intermediate_output.shape)"
      ],
      "metadata": {
        "id": "U2d7SbbD-rOG"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import cv2\n",
        "\n",
        "def deep_dream(input_image, model, steps=100, step_size=0.01):\n",
        "    for i in range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Compute the loss\n",
        "            loss, model_ = calc_loss(input_image, model)\n",
        "\n",
        "        # Get the gradients of the input image with respect to the loss\n",
        "        grads = tape.gradient(loss, input_image)\n",
        "\n",
        "        # Normalize the gradients\n",
        "        grads /= tf.math.reduce_std(grads) + 1e-8\n",
        "\n",
        "        # Update the input image\n",
        "        input_image += grads * step_size\n",
        "        input_image = tf.clip_by_value(input_image, 0, 255)\n",
        "\n",
        "    return input_image\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "OmM3xV-i-zEq"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deep_dream(input_image, model, steps=100, step_size=0.01):\n",
        "    # Define the loss and the optimizer\n",
        "    loss, intermediate_layer_model = calc_loss(input_image, model)\n",
        "    optimizer = tf.optimizers.SGD(learning_rate=step_size)\n",
        "\n",
        "    # Keep a list to hold the evolution of the image\n",
        "    image_list = []\n",
        "\n",
        "    # Run the optimization\n",
        "    for i in range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(input_image)\n",
        "            loss = calc_loss(input_image, model)[0]\n",
        "        grads, = tape.gradient(loss, input_image)\n",
        "        grads = tape.gradient(loss, input_image)\n",
        "        if grads is None:\n",
        "          return\n",
        "        optimizer.apply_gradients([(grads, input_image)])\n",
        "        image_list.append(input_image.numpy().copy())\n",
        "        \n",
        "    # Return the final image\n",
        "    return input_image"
      ],
      "metadata": {
        "id": "oGDW1-arNQ2B"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = cv2.resize(cv2.imread('/content/drive/MyDrive/Baghdad images/market.png'), (224, 224))\n",
        "\n",
        "#img = image.load_img(img_path, target_size=(224, 224))\n",
        "img = image.img_to_array(img)\n",
        "\n",
        "# Preprocess the image\n",
        "original_image = np.copy(img)\n",
        "#img = preprocess_input(np.expand_dims(img, axis=0))\n",
        "\n",
        "#input_image.set_shape([1,224,224,3])\n",
        "\n",
        "#input_image = tf.constant(img, dtype=tf.float32)\n",
        "#input_image = tf.expand_dims(input_image, axis=0)\n",
        "#input_image = tf.squeeze(input_image, axis=0)\n"
      ],
      "metadata": {
        "id": "nxvK56tl-4RJ"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to a Tensor\n",
        "input_image = tf.constant(img, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "dlBmRC1SBSW5"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the deep dream algorithm\n",
        "dream_img = deep_dream(input_image, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "gdaHmr4NBW4F",
        "outputId": "4e3f247e-dbeb-4bf8-d459-08e59746ea10"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-b14eebcfe038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the deep dream algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdream_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_dream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-92-27c78a6e0618>\u001b[0m in \u001b[0;36mdeep_dream\u001b[0;34m(input_image, model, steps, step_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deprocess the image\n",
        "dream_img = tf.clip_by_value(dream_img[0], 0, 255).numpy().astype('uint8')"
      ],
      "metadata": {
        "id": "STse05L8pTzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the original and dream images\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(121)\n",
        "plt.imshow(original_image.astype('uint8'))\n",
        "plt.axis('off')\n",
        "plt.title('Original Image')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(dream_img)\n",
        "plt.axis('off')\n",
        "plt.title('Dream Image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AZi2AMI2pXHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "_79yAOARnRXB",
        "outputId": "d3e10bc7-a050-4fe0-ace2-d6063a689dc7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-09c4ef33f56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Run the deep dream algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mdream_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_dream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Deprocess the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-09c4ef33f56c>\u001b[0m in \u001b[0;36mdeep_dream\u001b[0;34m(input_image, model, steps, step_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Normalize the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Update the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_std\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2420\u001b[0m   \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"reduce_std\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2422\u001b[0;31m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_variance\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2359\u001b[0m   \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"reduce_variance\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2360\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2361\u001b[0;31m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be either real or complex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2309\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m       gen_math_ops.mean(\n\u001b[0;32m-> 2311\u001b[0;31m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2312\u001b[0m           name=name))\n\u001b[1;32m   2313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_ReductionDims\u001b[0;34m(x, axis, reduction_indices)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;31m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mrank\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    814\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m   \"\"\"\n\u001b[0;32m--> 816\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mrank_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mrank_internal\u001b[0;34m(input, name, optimize)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                          as_ref=False):\n\u001b[1;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Function to calculate the loss\n",
        "def calc_loss(input_image, model):\n",
        "    input_image_batch = tf.expand_dims(input_image, axis=0)\n",
        "    preprocessed_input = preprocess_input(input_image_batch.numpy().copy())\n",
        "\n",
        "    # Get the activations of a specific layer\n",
        "    layer_name = \"conv5_block2_1_bn\"\n",
        "    intermediate_layer_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "    intermediate_output = intermediate_layer_model(preprocessed_input)\n",
        "\n",
        "\n",
        "    # Define the loss\n",
        "    loss = tf.math.reduce_mean(intermediate_output)\n",
        "    return loss, intermediate_layer_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def deep_dream(input_image, model, steps=100, step_size=0.01):\n",
        "    for i in range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Compute the loss\n",
        "            loss, model_ = calc_loss(input_image, model)\n",
        "\n",
        "        # Get the gradients of the input image with respect to the loss\n",
        "        grads = tape.gradient(loss, input_image)\n",
        "\n",
        "        # Normalize the gradients\n",
        "        grads /= tf.math.reduce_std(grads) + 1e-8\n",
        "\n",
        "        # Update the input image\n",
        "        input_image += grads * step_size\n",
        "        input_image = tf.clip_by_value(input_image, 0, 255)\n",
        "\n",
        "    return input_image\n",
        "\n",
        "\n",
        "# Load an image\n",
        "\n",
        "# Load an image\n",
        "#img_path = '/content/drive/MyDrive/Baghdad images/market.png'\n",
        "#img = cv2.imread(img_path)\n",
        "#img = cv2.resize(img, (224, 224))\n",
        "#img = np.array(img, dtype=float)\n",
        "\n",
        "# Preprocess the image\n",
        "#original_image = np.copy(img)\n",
        "#img = preprocess_input(np.expand_dims(img, axis=0))\n",
        "\n",
        "\n",
        "\n",
        "img_path = cv2.resize(cv2.imread('/content/drive/MyDrive/Baghdad images/market.png'), (224, 224))\n",
        "\n",
        "#img = image.load_img(img_path, target_size=(224, 224))\n",
        "img = image.img_to_array(img)\n",
        "\n",
        "# Preprocess the image\n",
        "original_image = np.copy(img)\n",
        "#img = preprocess_input(np.expand_dims(img, axis=0))\n",
        "\n",
        "#input_image.set_shape([1,224,224,3])\n",
        "\n",
        "#input_image = tf.constant(img, dtype=tf.float32)\n",
        "#input_image = tf.expand_dims(input_image, axis=0)\n",
        "#input_image = tf.squeeze(input_image, axis=0)\n",
        "\n",
        "# Convert the image to a Tensor\n",
        "input_image = tf.constant(img, dtype=tf.float32)\n",
        "\n",
        "# Run the deep dream algorithm\n",
        "dream_img = deep_dream(input_image, model)\n",
        "\n",
        "# Deprocess the image\n",
        "dream_img = tf.clip_by_value(dream_img[0], 0, 255).numpy().astype('uint8')\n",
        "\n",
        "# Plot the original and dream images\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(121)\n",
        "plt.imshow(original_image.astype('uint8'))\n",
        "plt.axis('off')\n",
        "plt.title('Original Image')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(dream_img)\n",
        "plt.axis('off')\n",
        "plt.title('Dream Image')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAMMWDlhOuaVjEMJRYCW+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}